2023-8-7 快手

### 一、问项目
**********很多

### 二、八股文
**1.mysql的InnoDB索引底层？**
答：B+树

**2.B+树的特点？**

答：
- 平衡性： B+树是一种平衡树，它能够保持相对平衡的高度，从而保证了查找、插入和删除操作的高效性能。每个节点的子节点数量在一定范围内，使得树的高度相对较低，从而减少了操作的时间复杂度。
- 多路搜索： B+树是一种多路搜索树，每个节点可以包含多个关键字（或数据），同时具有多个子节点。这意味着在每个节点上可以进行更多的搜索操作，从而减少了搜索路径的长度，提高了查找效率。
- 顺序访问： B+树的叶子节点形成了一个有序链表，通过这个链表可以实现范围查询和顺序访问。这对于数据库的范围查询操作非常有用，可以减少磁盘IO操作次数。
- 只在叶子节点存储数据： B+树的非叶子节点只存储索引信息，真正的数据都存储在叶子节点上。这样可以提高内存利用率，同时也有利于范围查询和顺序访问的优化。
- 节点分裂和合并： 当一个节点中的关键字数量超过一定限制时，会触发节点的分裂操作；当一个节点中的关键字数量过少时，会触发节点的合并操作。这种自动调整节点数量的机制保证了B+树的平衡性。
- 适应磁盘存储： B+树的结构和特点使得它适用于磁盘存储，减少了随机访问磁盘的次数，提高了IO效率。这对于数据库和文件系统等需要频繁读写磁盘的应用非常有益。
- 适用范围广泛： B+树被广泛应用于数据库管理系统、文件系统、索引结构等领域，它在处理大规模数据和高并发访问时表现优异。

**3.为什么B+树的非叶子节点不存储数据？**

答：
- 内存效率： 非叶子节点主要用于导航和定位到叶子节点，存储索引信息的开销相对较小。如果非叶子节点也存储数据，那么在内存中需要占用更多的空间，降低了内存效率。

- 减少IO操作： B+树通常用于磁盘存储和数据库系统等场景，其中磁盘IO是一个性能瓶颈。非叶子节点存储索引信息，可以减少磁盘IO操作次数，因为在进行索引导航时，可以更快速地找到具体的数据位置。

- 范围查询和顺序访问优化： B+树的叶子节点形成了一个有序链表，可以方便地进行范围查询和顺序访问。如果非叶子节点也存储数据，会使得链表中的数据不再连续，从而降低范围查询和顺序访问的效率。

- 节点分裂和合并： B+树的节点分裂和合并是根据关键字的数量来进行的，如果非叶子节点也存储数据，会增加管理和维护的复杂性。

总的来说，将数据存储在叶子节点而非叶子节点只存储索引信息，是为了在存储、内存、IO效率和查询性能等方面取得更好的平衡，特别是在大规模数据和磁盘存储的场景下，这种设计能够更好地满足性能需求。

**4.B+树与B树的区别？**

答：
B+树（B Plus Tree）和B树（B-Tree）是两种常用的树状数据结构，主要用于在数据库管理系统和文件系统等领域进行索引和数据存储。它们之间有一些关键的区别：

1. **叶子节点和非叶子节点存储数据：**
    - B树：B树的叶子节点和非叶子节点都可以存储数据，非叶子节点存储索引信息。
    - B+树：B+树的非叶子节点只存储索引信息，所有的数据都存储在叶子节点中。

2. **链表结构：**
    - B树：在B树中，叶子节点和非叶子节点之间没有明确的链表结构。
    - B+树：B+树的叶子节点形成了一个有序链表，可以支持范围查询和顺序访问。

3. **查询性能：**
    - B树：由于B树的非叶子节点也存储数据，相对于B+树，在查询时可能需要更多的磁盘IO操作，性能较低。
    - B+树：由于B+树的非叶子节点只存储索引信息，查询时通常需要的IO操作次数较少，性能相对较高。

4. **适应范围：**
    - B树：B树适用于随机访问和插入删除操作比较频繁的场景。
    - B+树：B+树适用于范围查询、顺序访问、磁盘存储等场景。

5. **节点分裂和合并：**
    - B树和B+树都有节点分裂和合并的机制，用于保持树的平衡性。但由于B+树的叶子节点存储了所有数据，分裂和合并的操作更加简单。

总的来说，B+树在许多方面优于B树，特别是在数据库管理系统和文件系统等需要进行范围查询、顺序访问和磁盘存储的场景下，B+树更加适合，因为它能够提供更好的查询性能和磁盘IO优化。

**5.通常在项目中，你是如何定位查询语句是否用了索引，以及如何优化**？

答：用explain看语句的执行计划。

**6.看你简历上有说重构mq封装模块？可以说说是什么重构封装的吗？**

**7.看你简历上有说解决重复消费问题，可以说说你是怎么解决的吗？**

答：加分布式锁，用redission。

**8.除了加锁的方法，还有其他的方法去解决重复消费的问题吗？**==【！！！没回答上来==】

答：
以下是一些常见的方法来解决消息队列重复消费的问题：

1. **消息去重：** 在消息生产者发送消息之前，可以在消息的内容中包含一个唯一标识符，比如消息ID。消费者在处理消息时，可以根据消息ID进行去重，确保同一个消息不会被处理多次。

2. **消费确认机制：** 消费者在处理完消息后，向消息队列发送确认消息。消息队列收到确认消息后才将消息标记为已消费。如果消费者处理消息失败或超时，消息队列可以重新发送相同的消息，直到收到确认消息为止。

3. **幂等性处理：** 在消费者处理消息时，可以设计处理逻辑具有幂等性，即多次执行相同的操作结果都是一样的。这样即使同一消息被重复处理，也不会产生副作用。

4. **消息过期时间：** 在消息发送时设置一个合理的过期时间。如果消费者在过期时间内没有处理消息，消息队列可以认为该消息已经失效，不再重复发送。

5. **消费者端限制：** 控制消费者的并发处理数量，避免过多的并发处理导致消息被重复消费。可以使用线程池或并发消费者来限制并发数量。

6. **分布式锁：** 在处理消息时使用分布式锁，确保同一消息在同一时间只能被一个消费者处理。这样可以避免多个消费者同时处理同一消息。

7. **日志记录：** 消费者在处理消息时，记录已经处理的消息信息，包括消息ID和处理结果。如果重复处理同一消息，可以根据日志进行排查和处理。

8. **幕等消费模式：** 使用特定的消息消费模式，如"Exactly Once"（仅一次）语义，确保每条消息只被消费一次。一些消息队列系统提供了这样的机制。

需要根据具体的应用场景和消息队列系统选择合适的方法来解决消息队列重复消费的问题。组合使用多种方法可以增强消息处理的可靠性和准确性。

**9.有没有考虑过假如mq的消息丢失情况怎么解决？**==【！！！没回答上来==】

答：
解决消息队列中消息丢失的问题是保障可靠性消息传递的关键。以下是一些方法来解决消息队列消息丢失的问题：

1. **持久化消息：** 确保消息队列中的消息在发送和接收过程中都得到持久化存储，即使系统崩溃也不会丢失。大多数消息队列系统都支持将消息持久化到磁盘，以确保消息的可靠性。

2. **消息确认机制：** 消费者在成功处理一条消息后，向消息队列发送确认消息，确保消息被正确处理并从队列中移除。如果消费者没有发送确认消息，消息队列会尝试重新发送消息，直到收到确认消息为止。

3. **消息重试：** 如果消息处理失败，可以设置消息队列系统进行自动重试。消息队列会将消息重新发送给消费者，直到处理成功为止。确保消息在失败情况下也能够被重试处理。

4. **消息监控和报警：** 设置监控和报警系统，及时检测到消息处理失败或者消息队列系统异常的情况。这样可以快速响应问题并进行修复，避免消息丢失。

5. **消息日志：** 在消息处理过程中，记录日志信息，包括消息的发送、接收、处理等关键步骤。这样在消息丢失问题发生时，可以通过日志进行排查和分析。

6. **分布式事务：** 对于需要跨多个服务或系统的操作，使用分布式事务来确保消息和业务逻辑的一致性。保证消息的发送和业务操作在一个原子操作内完成。

7. **备份和故障恢复：** 设置消息队列的备份机制，以防止主队列出现故障导致消息丢失。并定期测试备份的可用性和恢复能力。

8. **监控消息队列性能：** 监控消息队列的性能和负载，确保消息队列系统不会因为过载或性能问题而导致消息丢失。

9. **版本管理：** 在升级消息队列系统时，务必仔细阅读版本更新说明，了解是否有与消息可靠性相关的改进或问题修复。

综合使用上述方法，可以显著减少消息队列中消息丢失的风险，并提高系统的消息传递可靠性。

**10.redis的持久化方案有哪些？**

答：RDB和AOF。
Redis提供了两种主要的持久化方案：RDB（快照）和AOF（日志文件），每种方案都有其优点和缺点。

1. **RDB（快照）持久化：**
    - **优点：**
        - 性能高：RDB持久化通过生成数据库的快照，将数据保存在一个二进制文件中，读写性能较高，适用于备份和恢复。
        - 文件紧凑：快照文件是一个二进制文件，相对较小，占用的磁盘空间较少。
        - 适用于大数据：在大规模数据下，进行备份和恢复时RDB通常更快。
    - **缺点：**
        - 可能丢失部分数据：RDB持久化是定时生成快照，如果发生故障，在最后一次快照和故障之间的数据可能会丢失。
        - 不适用于实时数据：由于定时生成快照，如果在两次快照之间发生故障，会丢失一些数据。
        - 需要较多IO：生成快照需要耗费一定的IO资源，可能影响Redis的性能。

2. **AOF（日志文件）持久化：**
    - **优点：**
        - 数据安全性高：AOF持久化通过记录每条写操作的日志，可以在数据丢失时进行精确恢复，数据的安全性更高。
        - 实时性：AOF持久化可以根据配置实时记录写操作，较少数据丢失的风险。
        - 可读性：AOF日志文件是一个文本文件，易于查看和分析。
    - **缺点：**
        - 文件相对较大：由于记录每条写操作，AOF日志文件通常比RDB文件大。
        - 性能稍低：相对于RDB持久化，AOF持久化会稍微影响性能，尤其是在追加写操作日志时。
        - 恢复速度较慢：在大规模数据下，AOF恢复速度可能较慢。

3. **混合持久化（默认方式）：**
    - Redis也支持将RDB和AOF持久化方式同时使用，即混合持久化。可以通过AOF来提供较好的数据安全性，同时使用RDB来实现较好的性能和恢复速度。在重启时，可以先从AOF日志文件恢复数据，然后再通过加载RDB快照来快速恢复数据。

选择合适的持久化方案取决于应用的需求和优先级。如果数据安全性是关键，可以选择AOF持久化；如果性能和快速恢复更为重要，可以选择RDB持久化；而混合持久化可以在两者之间取得平衡。

**11.redis为什么快？**

Redis之所以快，有以下几个关键因素：

1. **内存存储：** Redis将数据存储在内存中，而不是磁盘上，这使得数据的读写速度非常快，因为内存访问速度远高于磁盘访问速度。这使得Redis特别适合于缓存和高速读写操作。

2. **单线程模型：** Redis采用单线程的事件循环模型，所有的命令都在单个线程中执行，避免了多线程之间的锁竞争和线程切换开销。虽然这可能在某些情况下限制了并发处理能力，但单线程模型降低了复杂性，并且允许Redis专注于最大程度地优化单个操作。

3. **非阻塞IO：** Redis使用非阻塞IO来处理多个客户端连接，在等待IO操作完成时，可以继续处理其他请求，提高了系统的并发性能。

4. **数据结构优化：** Redis支持多种高效的数据结构，如哈希表、有序集合、位图等，这些数据结构在特定场景下可以实现高效的操作。例如，使用哈希表实现了O(1)时间复杂度的读写操作。

5. **持久化优化：** Redis采用了RDB（快照）和AOF（日志文件）等持久化机制，这些机制在数据持久化和恢复方面都进行了优化，保证了数据的可靠性，同时不影响高速的读写操作。

6. **优化的网络协议：** Redis使用自定义的高效网络协议，减少了网络传输开销，提高了通信效率。

7. **C语言实现：** Redis是用C语言编写的，C语言具有较高的性能和效率，可以直接操作内存和底层操作系统接口，提高了Redis的性能。

8. **事件驱动架构：** Redis使用事件驱动的架构，通过事件循环处理客户端请求和IO操作，避免了多线程或多进程带来的开销，提高了系统的响应速度。

综合上述因素，Redis在内存存储、单线程模型、非阻塞IO、数据结构优化、持久化优化等方面的设计和实现，使其成为一个快速、高效的键值存储系统，适用于各种需要高性能和低延迟的应用场景。

**12.知道IO多路复用是怎么实现的吗？**==【！！！没回答上来==】

答：
在Redis中，IO多路复用是通过事件驱动的方式实现的，主要使用了操作系统提供的相关机制，如select、poll、epoll等，来监听多个文件描述符（sockets）的状态变化，从而实现高效的事件处理和异步IO操作。

具体来说，Redis中的IO多路复用包括以下步骤：

1. **创建事件循环：** Redis会创建一个事件循环，它会不断地监听文件描述符的状态变化，以及其他事件（如定时器等）。

2. **注册事件：** 在事件循环中，Redis会将需要监听的文件描述符注册到相应的IO多路复用机制中（如epoll）。这些文件描述符通常包括用于客户端连接、监听新连接、读写数据等。

3. **等待事件：** 事件循环会阻塞在等待事件的状态，当任何一个被注册的文件描述符有状态变化（如可读、可写等）时，事件循环会被唤醒。

4. **处理事件：** 一旦事件循环被唤醒，Redis会根据状态变化执行相应的操作，如处理客户端请求、读写数据等。

5. **循环重复：** 事件循环会持续循环执行上述步骤，以实现持续的事件监听和处理。

使用IO多路复用的好处在于，它能够避免创建大量的线程或进程来处理并发的IO操作，从而节省了资源并提高了性能。此外，IO多路复用还可以避免了频繁的上下文切换，提高了系统的响应速度。

在不同的操作系统上，Redis会使用不同的IO多路复用机制，例如，在Linux上会使用epoll，而在其他系统上可能会使用select或poll。这样，Redis可以充分利用操作系统提供的底层机制，实现高效的事件驱动和IO多路复用。

**13.询问了redis在项目中的使用情况。**

**14.redis的集群的数据切片是怎么切的？**

答：
在Redis集群中，数据切片是将整个数据集分散存储在多个节点上的过程，以实现数据的分布式存储和负载均衡。Redis集群使用哈希槽（Hash Slot）的概念来进行数据切片，具体实现如下：

1. **哈希槽的定义：** Redis将所有可能的数据划分为一定数量的哈希槽，通常是16384个。每个哈希槽都有一个唯一的编号，范围从0到16383。

2. **数据的哈希映射：** 当需要将数据存储到集群中时，Redis会使用数据的某个属性（通常是键）进行哈希运算，得到一个哈希值，然后将这个哈希值对16384取模，得到对应的哈希槽编号。

3. **数据分配：** Redis集群中的每个节点负责一部分哈希槽。当一个节点加入集群或者有节点发生变动时，集群会根据负载均衡的策略，将部分哈希槽分配给新的节点或重新分配给其他节点。这样，每个节点都持有一些哈希槽的数据。

4. **数据访问：** 当客户端发送读写请求到Redis集群时，集群会根据请求的键进行哈希运算，找到对应的哈希槽，然后确定存储该数据的节点。客户端与节点直接通信，进行数据的读写操作。

5. **数据迁移：** 当节点发生变动时（如节点加入、节点移除、数据迁移等），可能会涉及到哈希槽的重新分配和数据的迁移。数据迁移过程需要保证数据的一致性和可用性。

通过以上步骤，Redis集群实现了数据的切片和分布式存储。每个节点负责一部分哈希槽的数据，从而实现了负载均衡和横向扩展。哈希槽的分布和数据切片策略可以保证数据在集群中的均匀分布，避免了热点数据的问题，同时也允许集群规模的扩大。

### 三、算法
反转从位置 m 到 n 的链表。请使用一趟扫描完成反转。==【思想方案说对了，代码没写出来】==
说明:
1 ≤ m ≤ n ≤ 链表长度。

示例:
输入: 1->2->3->4->5->NULL, m = 2, n = 4
输出: 1->4->3->2->5->NULL

反转链表中的第m至第n个节点是一个常见的链表操作，可以通过遍历和指针操作来实现。下面是Java实现的详细步骤：

首先，假设链表的数据结构定义如下：

```java
class ListNode {
    int val;
    ListNode next;
    ListNode(int val) {
        this.val = val;
    }
}
```

然后，可以按照以下步骤实现反转链表中第m至第n个节点的操作：

1. 定义两个指针：`prev` 和 `curr`，分别表示当前节点的前一个节点和当前节点。

2. 使用一个额外的指针 `dummy`，初始化为一个虚拟节点，将其 `next` 指向链表的头节点。

3. 将 `prev` 移动到第 `m-1` 个节点，将 `curr` 移动到第 `m` 个节点。

4. 使用一个额外的指针 `startPrev` 记录 `prev` 的初始位置，用于最后连接反转后的子链表。

5. 开始反转第 `m` 至第 `n` 个节点，需要反转次数为 `n-m+1` 次。
    - 在每一次反转中，使用一个临时指针 `nextTemp` 来记录 `curr` 的下一个节点，然后将 `curr` 的 `next` 指向 `prev`，完成节点反转。
    - 然后将 `prev` 和 `curr` 向前移动一个位置，即 `prev = curr`，`curr = nextTemp`。

6. 反转结束后，将 `startPrev` 的 `next` 指向 `prev`，将反转后的子链表与原链表连接起来。

7. 返回虚拟节点 `dummy` 的 `next`，即为反转后的链表。

以下是实现的代码示例：

```java

public class ReverseBetweenLinkedList {
    public ListNode reverseBetween(ListNode head, int m, int n) {
        if (head == null || m == n) {
            return head;
        }

        // 创建虚拟节点，并将其指向链表头部
        ListNode dummy = new ListNode(0);
        dummy.next = head;
        ListNode prev = dummy;

        // 定位到第 m-1 个节点，用 prev 指针指向它
        for (int i = 0; i < m - 1; i++) {
            prev = prev.next;
        }

        // 记录 prev 初始位置，用于连接反转后的子链表
        ListNode startPrev = prev;

        // 开始反转操作，需要反转 n-m+1 次
        ListNode curr = prev.next;
        ListNode nextTemp;

        for (int i = 0; i < n - m + 1; i++) {
            nextTemp = curr.next;  // 记录当前节点的下一个节点
            curr.next = prev;      // 反转操作：将当前节点的 next 指向 prev
            prev = curr;           // prev 向前移动
            curr = nextTemp;       // curr 向前移动
        }

        // 连接反转后的子链表与原链表
        startPrev.next.next = curr;
        startPrev.next = prev;

        // 返回虚拟节点的 next，即为反转后的链表头部
        return dummy.next;
    }

    public static void main(String[] args) {
        // 创建一个示例链表: 1 -> 2 -> 3 -> 4 -> 5
        ListNode head = new ListNode(1);
        head.next = new ListNode(2);
        head.next.next = new ListNode(3);
        head.next.next.next = new ListNode(4);
        head.next.next.next.next = new ListNode(5);

        ReverseBetweenLinkedList solution = new ReverseBetweenLinkedList();
        int m = 2;
        int n = 4;
        ListNode reversedHead = solution.reverseBetween(head, m, n);

        // 输出反转后的链表
        ListNode current = reversedHead;
        while (current != null) {
            System.out.print(current.val + " ");
            current = current.next;
        }
    }
}

```

这段代码实现了反转链表中第m至第n个节点的操作。它首先定位到第m个节点的前一个节点 `prev`，然后通过遍历和指针操作，将第m至第n个节点进行反转，最后将反转后的子链表与原链表连接起来。